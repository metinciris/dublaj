# Ä°ngilizce Videodan TÃ¼rkÃ§e Dublaj: Whisper + ChatGPT + Edge-TTS

Bu proje, yerel bilgisayarÄ±nda ÅŸu sÄ±rayÄ± gerÃ§ekleÅŸtirmek iÃ§in basit bir pipeline saÄŸlar:

1. **Whisper** ile Ä°ngilizce video sesini zaman uyumlu **SRT altyazÄ±ya** Ã§evirme  
2. **ChatGPT** ile (manuel) SRT metnindeki hatalarÄ± dÃ¼zeltme / TÃ¼rkÃ§e Ã§eviri Ã¼retme  
3. DÃ¼zeltilmiÅŸ **TÃ¼rkÃ§e .srt** dosyasÄ±nÄ± Python ve **Edge-TTS** kullanarak **TÃ¼rkÃ§e ses dosyasÄ±na (dublaj)** Ã§evirme  
4. Ä°steÄŸe baÄŸlÄ±: **FFmpeg** ile bu TÃ¼rkÃ§e sesi videoya **ek ses parÃ§asÄ±** olarak gÃ¶mme

> Not: Bu repo, her adÄ±mÄ± otomatikleÅŸtirmek yerine, **pratik bir workflow** ve yardÄ±mcÄ± scriptler sunar.  
> Whisper ve ChatGPT ile metin dÃ¼zeltme / Ã§eviri kÄ±smÄ± **manuel** yapÄ±lÄ±r.

---

## ğŸ§° Gereksinimler

- Python 3.13.x (veya edge-tts ile uyumlu bir 3.x sÃ¼rÃ¼mÃ¼)
- `pip`
- (Whisper iÃ§in) PyTorch + `whisper`
- (Ä°steÄŸe baÄŸlÄ±) [FFmpeg](https://ffmpeg.org/) â€“ videoya ses eklemek iÃ§in

Python paketleri:

```bash
pip install edge-tts srt
# Whisper iÃ§in (zaten yÃ¼klÃ¼yse tekrar gerek yok)
pip install -U openai-whisper
````

AyrÄ±ca bu repodaki `requirements.txt`:

```text
edge-tts
srt
openai-whisper
```

---

## ğŸ” Genel AkÄ±ÅŸ

### 1. Ä°ngilizce ses â†’ Ä°ngilizce SRT (Whisper)

Ã–rneÄŸin `input_en.mp3` dosyan olsun:

```bash
python -m whisper input_en.mp3 --model large --language en --task transcribe --output_format srt
```

Bu komut, aynÄ± klasÃ¶re yaklaÅŸÄ±k ÅŸu isimde bir dosya Ã¼retir:

```text
input_en.srt
```

### Alternatif altyazÄ± oluÅŸturma
```bash
python -m whisper "english.mp3" --model large --language en --task transcribe
```
âš ï¸ Bu komut %100 Ã§alÄ±ÅŸÄ±r, Ã§Ã¼nkÃ¼ whisper komutunu PATH'e eklemeye gerek kalmaz.

Bu iÅŸlem bitince klasÃ¶rde otomatik olarak ÅŸunlar oluÅŸacak:

uscap.srt â†’ âœ”ï¸ Ä°ngilizce altyazÄ±

uscap.txt â†’ metin dosyasÄ±

uscap.vtt â†’ web altyazÄ±sÄ±

---

### 2. Ä°ngilizce SRTâ€™yi dÃ¼zeltme (ChatGPT ile manuel)

Bu adÄ±m **bilerek manuel** bÄ±rakÄ±lmÄ±ÅŸtÄ±r:

1. `input_en.srt` iÃ§indeki metni al
2. ChatGPTâ€™ye yapÄ±ÅŸtÄ±r:

   * â€œLÃ¼tfen aÅŸaÄŸÄ±daki altyazÄ± metnini imla/hata aÃ§Ä±sÄ±ndan dÃ¼zelt.â€
3. DÃ¼zeltmiÅŸ Ä°ngilizce metni istersen tekrar `.srt` formatÄ±nda dÃ¼zenle

Ä°stersen bu aÅŸamada:

* Ä°ngilizce â†’ TÃ¼rkÃ§e Ã§eviriyi de ChatGPTâ€™den isteyebilirsin
* Ã‡eviriyi **SRT formatÄ±na sadÄ±k** olacak ÅŸekilde al: zaman kodlarÄ± aynÄ±, iÃ§erik TÃ¼rkÃ§e

SonuÃ§ta elinde ÅŸu dosya olmalÄ±:

```text
subtitles_tr.srt   # TÃ¼rkÃ§e, zaman kodlarÄ± korunmuÅŸ altyazÄ±
```

---

### 3. TÃ¼rkÃ§e SRT â†’ TÃ¼rkÃ§e ses (Edge-TTS)

`subtitles_tr.srt` dosyasÄ±nÄ± `scripts/srt_to_turkish_tts.py` ile aynÄ± klasÃ¶re koy veya yolu ona gÃ¶re gÃ¼ncelle.

Script: [`scripts/srt_to_turkish_tts.py`](scripts/srt_to_turkish_tts.py)

```bash
cd scripts
python srt_to_turkish_tts.py
```

VarsayÄ±lan ayarlar:

* Girdi: `altyazi.srt` (aynÄ± klasÃ¶rde)
* Ã‡Ä±ktÄ±: `turkce_ses.wav`
* Ses: `tr-TR-EmelNeural` (TÃ¼rkÃ§e kadÄ±n sesi)

Bu dosyayÄ± **dublaj** olarak kullanacaÄŸÄ±z.

---

### 4. TÃ¼rkÃ§e sesi videoya eklemek (FFmpeg)

Elinde:

* Orijinal video: `video.mp4`
* Ãœretilen TÃ¼rkÃ§e ses: `turkce_ses.wav`

Videoya **ek ses parÃ§asÄ±** olarak eklemek iÃ§in:

```bash
ffmpeg -i video.mp4 -i turkce_ses.wav \
  -map 0:v -map 0:a -map 1:a \
  -c:v copy -c:a aac -shortest \
  video_tr_dub.mp4
```

Bu komut:

* GÃ¶rÃ¼ntÃ¼yÃ¼ yeniden kodlamadan **kopyalar** (`-c:v copy`)
* Orijinal ses + TÃ¼rkÃ§e ses olacak ÅŸekilde birden fazla ses parÃ§asÄ± ekler
* KÄ±saysa ses veya video farkÄ±nda, en kÄ±sa olana gÃ¶re kÄ±rpar (`-shortest`)

Sadece TÃ¼rkÃ§e sesli bir Ã§Ä±ktÄ± istersen:

```bash
ffmpeg -i video.mp4 -i turkce_ses.wav \
  -map 0:v -map 1:a \
  -c:v copy -c:a aac -shortest \
  video_tr_only.mp4
```

---

## ğŸ“œ `scripts/srt_to_turkish_tts.py`

Bu script, Python 3.13 ile uyumlu olacak ÅŸekilde **pydub kullanmadan**, sadece `edge-tts`, `srt` ve standart `wave` modÃ¼lÃ¼yle Ã§alÄ±ÅŸÄ±r.

```python
import asyncio
import wave
import os
import srt
import edge_tts

# ==========================
# KullanÄ±cÄ± ayarlarÄ±
# ==========================

SRT_DOSYASI = "altyazi.srt"        # TÃ¼rkÃ§e altyazÄ± dosyan
CIKTI_DOSYASI = "turkce_ses.wav"   # Ãœretilecek ses dosyasÄ±
VOICE = "tr-TR-EmelNeural"         # TÃ¼rkÃ§e kadÄ±n ses


async def generate_segment(text: str, filename: str):
    """
    Edge TTS kullanarak verilen metni WAV dosyasÄ±na kaydeder.
    """
    communicate = edge_tts.Communicate(text=text, voice=VOICE)
    await communicate.save(filename)


def merge_waves(segments, output_path):
    """
    Segment WAV dosyalarÄ±nÄ± zaman damgalarÄ±na gÃ¶re birleÅŸtirir.
    Edge TTS'in Ã¼rettiÄŸi WAV'ler tipik olarak 24000 Hz, mono, 16-bit olur.
    """
    framerate = 24000
    sampwidth = 2
    nchannels = 1

    final_frames = bytearray()

    for start_ms, wav_path in segments:
        # Åu ana kadar Ã¼retilen sesin sÃ¼resi (ms)
        current_ms = int(len(final_frames) / (framerate * sampwidth * nchannels) * 1000)

        # Gerekirse sessizlik ekle
        if start_ms > current_ms:
            silence_ms = start_ms - current_ms
            silence_samples = int(framerate * (silence_ms / 1000))
            final_frames.extend(b"\x00\x00" * silence_samples)

        # WAV dosyasÄ±nÄ± ekle
        with wave.open(wav_path, "rb") as w:
            final_frames.extend(w.readframes(w.getnframes()))

    # Son WAV dosyasÄ±nÄ± yaz
    with wave.open(output_path, "wb") as out:
        out.setnchannels(nchannels)
        out.setsampwidth(sampwidth)
        out.setframerate(framerate)
        out.writeframes(final_frames)

    print("TamamlandÄ±:", output_path)


async def main():
    # 1) SRT dosyasÄ±nÄ± oku
    with open(SRT_DOSYASI, "r", encoding="utf-8") as f:
        subtitles = list(srt.parse(f.read()))

    segments = []

    # 2) Her altyazÄ± satÄ±rÄ± iÃ§in Edge TTS ile geÃ§ici ses Ã¼ret
    for i, sub in enumerate(subtitles):
        text = sub.content.replace("\n", " ").strip()
        if not text:
            continue

        start_ms = int(sub.start.total_seconds() * 1000)
        temp_file = f"segment_{i}.wav"

        print(f"[{i+1}/{len(subtitles)}] Ses Ã¼retiliyor: {text!r}")

        await generate_segment(text, temp_file)
        segments.append((start_ms, temp_file))

    # 3) Segmentleri zaman damgalarÄ±na gÃ¶re birleÅŸtir
    merge_waves(segments, CIKTI_DOSYASI)

    # 4) GeÃ§ici dosyalarÄ± temizle
    for _, fpath in segments:
        if os.path.exists(fpath):
            os.remove(fpath)


if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ” Notlar

* **Whisper hatalarÄ±nÄ±n dÃ¼zeltilmesi** ve **TÃ¼rkÃ§e Ã§eviri** adÄ±mÄ± bilinÃ§li olarak manuel:

  * ChatGPT veya baÅŸka bir LLM ile dilediÄŸin promptâ€™u kullanabilirsin.
  * Ä°stersen sadece yazÄ±m hatasÄ± dÃ¼zelt, istersen aynÄ± anda Ã§eviri ve sadeleÅŸtirme iste.
* Edge-TTS internet baÄŸlantÄ±sÄ± gerektirir; tamamen offline bir Ã§Ã¶zÃ¼m istersen, Silero TTS gibi local modeller eklenebilir (bu repo ÅŸimdilik Edge-TTS odaklÄ±).

---

## ğŸ§¾ Lisans

Ä°stediÄŸin lisansÄ± buraya ekleyebilirsin (MIT, Apache-2.0, vb.).

```
